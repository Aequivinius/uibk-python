{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "73cf49f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "\n",
    "def traverse_directory(path):\n",
    "  return [os.path.join(path, f) for f in os.listdir(path) if os.path.isfile(os.path.join(path, f))]\n",
    "\n",
    "  onlyfiles = []\n",
    "  files_directories = os.listdir(path)\n",
    "  for f in files_directories:\n",
    "        fpath = os.path.join(path, f)\n",
    "  \n",
    "  if os.path.isfile(fpath):\n",
    "        onlyfiles.add(fpath)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c12c8de1",
   "metadata": {},
   "source": [
    "# Word-counter\n",
    "\n",
    "This program was written to count word occurences in Shakespeare texts.\n",
    "\n",
    "Above, a list with all files in the corpus is generated, while everything after the return statement is of course ignored by python, it makes understandig easier.\n",
    "\n",
    "Below, the generated list is tokenized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3a57f357",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_file(path):\n",
    "  f = open(path)\n",
    "  content = f.read()\n",
    "  tokens = content.split()\n",
    "  normalized_tokens = [token.lower().strip(\"()[]!#'.,;:<>?+_=-'@^&*\") for token in tokens]\n",
    "\n",
    "  for token in normalized_tokens:\n",
    "      if len(token) == 0:\n",
    "          normalized_tokens.remove(token)\n",
    "  return normalized_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7bdad2f",
   "metadata": {},
   "source": [
    "The counting process starts at this point, after which the counts are sorted using tuples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f3cd7cd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_counts(pathlist):\n",
    "  counts = {}\n",
    "  for path in pathlist:\n",
    "    tokens = tokenize_file(path)\n",
    "    \n",
    "  for token in tokens:\n",
    "      if token in counts:\n",
    "        counts[token] = counts[token] + 1\n",
    "      else:\n",
    "        counts[token] = 1\n",
    "        \n",
    "  return counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fdc34fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_counts(counts):\n",
    "  sorted_tuples = sorted(counts.items(), key=lambda item: item[1], reverse=True)\n",
    "  return sorted_tuples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c59931d",
   "metadata": {},
   "source": [
    "After the counting process is finished, the list of all counts is written to a .csv file.\n",
    "\n",
    "Lastly the functions are called. In this particular case the origin directory is called _corpus_ and the output file _frequencies.csv_.\n",
    "\n",
    "In order to keep the previous program intact an additional function reads the first 100 lines of the .csv output file and prints them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "72744e44",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_frequencies(frequencies, path):\n",
    "  counter = 0\n",
    "  sum_all_counts = 0\n",
    "  for element in frequencies:\n",
    "    sum_all_counts = sum_all_counts + element[1]\n",
    "    \n",
    "  with open(path, 'w') as f:\n",
    "    for element in frequencies:\n",
    "      frequency = element[1]/sum_all_counts\n",
    "      f.write(str(counter) + \",\" + element[0] + \",\" + str(element[1]) + \",\" + str(frequency) + \"\\n\")\n",
    "\n",
    "    counter += counter\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "04691d87",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_print_frequencies(path):\n",
    "    with open(path, 'r') as z:\n",
    "        reader = csv.reader(z)\n",
    "        lines = 0\n",
    "    \n",
    "        for row in reader:\n",
    "            print(row[1], row[2])\n",
    "            lines += 1\n",
    "            if lines >= 100:\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bc21e402",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the 338\n",
      "and 326\n",
      "to 194\n",
      "his 182\n",
      "she 164\n",
      "her 153\n",
      "a 144\n",
      "in 143\n",
      "he 132\n",
      "of 126\n",
      "with 120\n",
      "that 107\n",
      "is 87\n",
      "not 80\n",
      "i 79\n",
      "but 76\n",
      "my 75\n",
      "for 72\n",
      "as 70\n",
      "so 69\n",
      "thou 68\n",
      "it 67\n",
      "be 61\n",
      "him 59\n",
      "love 59\n",
      "on 56\n",
      "thy 55\n",
      "by 50\n",
      "like 50\n",
      "this 50\n",
      "doth 47\n",
      "all 46\n",
      "now 45\n",
      "their 41\n",
      "or 40\n",
      "thee 40\n",
      "they 40\n",
      "no 37\n",
      "shall 36\n",
      "me 36\n",
      "from 35\n",
      "will 32\n",
      "at 32\n",
      "eyes 32\n",
      "are 31\n",
      "what 31\n",
      "more 30\n",
      "being 30\n",
      "which 29\n",
      "if 28\n",
      "one 28\n",
      "heart 28\n",
      "hath 27\n",
      "them 27\n",
      "would 26\n",
      "when 26\n",
      "was 25\n",
      "then 25\n",
      "did 25\n",
      "yet 24\n",
      "lips 24\n",
      "whose 24\n",
      "have 23\n",
      "never 22\n",
      "where 22\n",
      "were 22\n",
      "fair 22\n",
      "beauty 21\n",
      "should 21\n",
      "eye 21\n",
      "still 20\n",
      "face 20\n",
      "do 20\n",
      "who 20\n",
      "upon 20\n",
      "had 19\n",
      "kiss 19\n",
      "adonis 18\n",
      "how 18\n",
      "fear 18\n",
      "sweet 18\n",
      "night 18\n",
      "make 18\n",
      "quoth 18\n",
      "your 17\n",
      "you 17\n",
      "o 17\n",
      "sun 16\n",
      "tears 16\n",
      "mine 16\n",
      "may 15\n",
      "even 15\n",
      "each 15\n",
      "again 15\n",
      "light 15\n",
      "death 15\n",
      "boar 15\n",
      "fire 14\n",
      "there 14\n",
      "till 13\n"
     ]
    }
   ],
   "source": [
    "files = traverse_directory('corpus')\n",
    "counts = compute_counts(files)\n",
    "sorted_counts = sort_counts(counts)\n",
    "write_frequencies(sorted_counts, 'frequencies.csv')\n",
    "read_print_frequencies('frequencies.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41bee896",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
