{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "deddb888",
   "metadata": {},
   "source": [
    "# Functions for frequency list generations "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e764173d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['exercise-5/corpus\\\\a-midsummer-nights-dream_TXT_FolgerShakespeare.txt', 'exercise-5/corpus\\\\alls-well-that-ends-well_TXT_FolgerShakespeare.txt', 'exercise-5/corpus\\\\antony-and-cleopatra_TXT_FolgerShakespeare.txt', 'exercise-5/corpus\\\\as-you-like-it_TXT_FolgerShakespeare.txt', 'exercise-5/corpus\\\\coriolanus_TXT_FolgerShakespeare.txt']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "path_to_corpus=\"exercise-5/corpus\"\n",
    "\n",
    "def traverse_directory(path):\n",
    "  return [os.path.join(path, f) for f in os.listdir(path) if os.path.isfile(os.path.join(path, f))]\n",
    "\n",
    "files = traverse_directory(path_to_corpus)\n",
    "print(files[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92d0939b",
   "metadata": {},
   "source": [
    "Here we list all the files in the file path. For this demonstration we will use Shakespeare texts located in my local directory `corpus`. For pragmatic purposes only the first five elements of the list are printed out.\n",
    "\n",
    "(This applies also to the following demonstrations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "df4b2b03",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_file(path):\n",
    "  with open(path, \"r\") as f:\n",
    "    complete_string = f.read()\n",
    "    tokens = []\n",
    "    normalized_tokens = []\n",
    "    tokens = complete_string.split()\n",
    "\n",
    "  for token in tokens:\n",
    "    normalized_tokens.append(token.lower().strip(\",;.!?[]()=-\"))\n",
    "  \n",
    "  while (\"\" in normalized_tokens):\n",
    "    normalized_tokens.remove(\"\")\n",
    "  \n",
    "  return normalized_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80f6161f",
   "metadata": {},
   "source": [
    "This function takes a path to a text file, reads out the string contained, tokenizes and normalizes it and returns a list of normalized tokens. We will see it at work in the next code snippet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "6eb7313c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('a', 15612), ('midsummer', 4), (\"night's\", 29), ('dream', 126), ('by', 4147)]\n"
     ]
    }
   ],
   "source": [
    "def compute_counts(pathlist):\n",
    "  counts = {}\n",
    "  for path in pathlist:\n",
    "    tokens = tokenize_file(path)\n",
    "    for token in tokens:\n",
    "      if token in counts:\n",
    "        counts[token] = counts[token] + 1\n",
    "      else:\n",
    "        counts[token] = 1\n",
    "\n",
    "  return counts\n",
    "\n",
    "counts = compute_counts(files)\n",
    "\n",
    "print(list(counts.items())[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4ea176d",
   "metadata": {},
   "source": [
    "Here we see how the `compute_counts functions` utilizes the `tokenize_file` function to generate a dictionary with the normalized tokens as keys and their respective frequencies as values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "16a0d70d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('the', 29236), ('and', 28282), ('to', 21909), ('i', 21130), ('of', 18432)]\n"
     ]
    }
   ],
   "source": [
    "def sort_counts(counts):\n",
    "  sorted_tuples = sorted(counts.items(), key=lambda item: item[1], reverse=True)\n",
    "  return sorted_tuples\n",
    "\n",
    "\n",
    "sorted_counts = sort_counts(counts)\n",
    "\n",
    "print(sorted_counts[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "223e2fdb",
   "metadata": {},
   "source": [
    "`soirt_counts` creates a sorted list that contains each key-value-paire as tuples in one list element. The token with the highest count appears first, the following tokens appear in descending order.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2967690",
   "metadata": {},
   "source": [
    "# Results\n",
    "\n",
    "Now that we have defined all functions and modified the corpus inputs, we can output the 100 most frequent words used in the Shakespeare corpus using a final function:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "a1274dfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rank   1\t|\tWord: the\t|\tCount: 29236\t|\tFrequency: 3.042%\n",
      "\n",
      "Rank   2\t|\tWord: and\t|\tCount: 28282\t|\tFrequency: 2.943%\n",
      "\n",
      "Rank   3\t|\tWord: to\t|\tCount: 21909\t|\tFrequency: 2.280%\n",
      "\n",
      "Rank   4\t|\tWord: i \t|\tCount: 21130\t|\tFrequency: 2.199%\n",
      "\n",
      "Rank   5\t|\tWord: of\t|\tCount: 18432\t|\tFrequency: 1.918%\n",
      "\n",
      "Rank   6\t|\tWord: a \t|\tCount: 15612\t|\tFrequency: 1.624%\n",
      "\n",
      "Rank   7\t|\tWord: you\t|\tCount: 14548\t|\tFrequency: 1.514%\n",
      "\n",
      "Rank   8\t|\tWord: my\t|\tCount: 13055\t|\tFrequency: 1.358%\n",
      "\n",
      "Rank   9\t|\tWord: in\t|\tCount: 11916\t|\tFrequency: 1.240%\n",
      "\n",
      "Rank  10\t|\tWord: that\t|\tCount: 11693\t|\tFrequency: 1.217%\n",
      "\n",
      "Rank  11\t|\tWord: is\t|\tCount: 9851\t|\tFrequency: 1.025%\n",
      "\n",
      "Rank  12\t|\tWord: not\t|\tCount: 8965\t|\tFrequency: 0.933%\n",
      "\n",
      "Rank  13\t|\tWord: with\t|\tCount: 8611\t|\tFrequency: 0.896%\n",
      "\n",
      "Rank  14\t|\tWord: me\t|\tCount: 8121\t|\tFrequency: 0.845%\n",
      "\n",
      "Rank  15\t|\tWord: for\t|\tCount: 8089\t|\tFrequency: 0.842%\n",
      "\n",
      "Rank  16\t|\tWord: it\t|\tCount: 8069\t|\tFrequency: 0.840%\n",
      "\n",
      "Rank  17\t|\tWord: he\t|\tCount: 7928\t|\tFrequency: 0.825%\n",
      "\n",
      "Rank  18\t|\tWord: his\t|\tCount: 7640\t|\tFrequency: 0.795%\n",
      "\n",
      "Rank  19\t|\tWord: be\t|\tCount: 7269\t|\tFrequency: 0.756%\n",
      "\n",
      "Rank  20\t|\tWord: your\t|\tCount: 7040\t|\tFrequency: 0.732%\n",
      "\n",
      "Rank  21\t|\tWord: this\t|\tCount: 7006\t|\tFrequency: 0.729%\n",
      "\n",
      "Rank  22\t|\tWord: as\t|\tCount: 6952\t|\tFrequency: 0.723%\n",
      "\n",
      "Rank  23\t|\tWord: but\t|\tCount: 6668\t|\tFrequency: 0.694%\n",
      "\n",
      "Rank  24\t|\tWord: have\t|\tCount: 6236\t|\tFrequency: 0.649%\n",
      "\n",
      "Rank  25\t|\tWord: thou\t|\tCount: 5865\t|\tFrequency: 0.610%\n",
      "\n",
      "Rank  26\t|\tWord: him\t|\tCount: 5541\t|\tFrequency: 0.577%\n",
      "\n",
      "Rank  27\t|\tWord: so\t|\tCount: 5353\t|\tFrequency: 0.557%\n",
      "\n",
      "Rank  28\t|\tWord: will\t|\tCount: 5266\t|\tFrequency: 0.548%\n",
      "\n",
      "Rank  29\t|\tWord: what\t|\tCount: 4655\t|\tFrequency: 0.484%\n",
      "\n",
      "Rank  30\t|\tWord: her\t|\tCount: 4619\t|\tFrequency: 0.481%\n",
      "\n",
      "Rank  31\t|\tWord: thy\t|\tCount: 4329\t|\tFrequency: 0.450%\n",
      "\n",
      "Rank  32\t|\tWord: all\t|\tCount: 4285\t|\tFrequency: 0.446%\n",
      "\n",
      "Rank  33\t|\tWord: by\t|\tCount: 4147\t|\tFrequency: 0.431%\n",
      "\n",
      "Rank  34\t|\tWord: do\t|\tCount: 4042\t|\tFrequency: 0.421%\n",
      "\n",
      "Rank  35\t|\tWord: no\t|\tCount: 4008\t|\tFrequency: 0.417%\n",
      "\n",
      "Rank  36\t|\tWord: shall\t|\tCount: 3840\t|\tFrequency: 0.400%\n",
      "\n",
      "Rank  37\t|\tWord: if\t|\tCount: 3748\t|\tFrequency: 0.390%\n",
      "\n",
      "Rank  38\t|\tWord: are\t|\tCount: 3676\t|\tFrequency: 0.382%\n",
      "\n",
      "Rank  39\t|\tWord: we\t|\tCount: 3538\t|\tFrequency: 0.368%\n",
      "\n",
      "Rank  40\t|\tWord: they\t|\tCount: 3484\t|\tFrequency: 0.362%\n",
      "\n",
      "Rank  41\t|\tWord: on\t|\tCount: 3412\t|\tFrequency: 0.355%\n",
      "\n",
      "Rank  42\t|\tWord: thee\t|\tCount: 3357\t|\tFrequency: 0.349%\n",
      "\n",
      "Rank  43\t|\tWord: our\t|\tCount: 3284\t|\tFrequency: 0.342%\n",
      "\n",
      "Rank  44\t|\tWord: lord\t|\tCount: 3113\t|\tFrequency: 0.324%\n",
      "\n",
      "Rank  45\t|\tWord: now\t|\tCount: 2983\t|\tFrequency: 0.310%\n",
      "\n",
      "Rank  46\t|\tWord: from\t|\tCount: 2936\t|\tFrequency: 0.305%\n",
      "\n",
      "Rank  47\t|\tWord: she\t|\tCount: 2914\t|\tFrequency: 0.303%\n",
      "\n",
      "Rank  48\t|\tWord: good\t|\tCount: 2883\t|\tFrequency: 0.300%\n",
      "\n",
      "Rank  49\t|\tWord: king\t|\tCount: 2842\t|\tFrequency: 0.296%\n",
      "\n",
      "Rank  50\t|\tWord: sir\t|\tCount: 2792\t|\tFrequency: 0.290%\n",
      "\n",
      "Rank  51\t|\tWord: at\t|\tCount: 2717\t|\tFrequency: 0.283%\n",
      "\n",
      "Rank  52\t|\tWord: or\t|\tCount: 2632\t|\tFrequency: 0.274%\n",
      "\n",
      "Rank  53\t|\tWord: come\t|\tCount: 2545\t|\tFrequency: 0.265%\n",
      "\n",
      "Rank  54\t|\tWord: which\t|\tCount: 2516\t|\tFrequency: 0.262%\n",
      "\n",
      "Rank  55\t|\tWord: enter\t|\tCount: 2506\t|\tFrequency: 0.261%\n",
      "\n",
      "Rank  56\t|\tWord: more\t|\tCount: 2491\t|\tFrequency: 0.259%\n",
      "\n",
      "Rank  57\t|\tWord: would\t|\tCount: 2460\t|\tFrequency: 0.256%\n",
      "\n",
      "Rank  58\t|\tWord: was\t|\tCount: 2425\t|\tFrequency: 0.252%\n",
      "\n",
      "Rank  59\t|\tWord: then\t|\tCount: 2400\t|\tFrequency: 0.250%\n",
      "\n",
      "Rank  60\t|\tWord: their\t|\tCount: 2367\t|\tFrequency: 0.246%\n",
      "\n",
      "Rank  61\t|\tWord: am\t|\tCount: 2296\t|\tFrequency: 0.239%\n",
      "\n",
      "Rank  62\t|\tWord: o \t|\tCount: 2249\t|\tFrequency: 0.234%\n",
      "\n",
      "Rank  63\t|\tWord: how\t|\tCount: 2245\t|\tFrequency: 0.234%\n",
      "\n",
      "Rank  64\t|\tWord: here\t|\tCount: 2244\t|\tFrequency: 0.233%\n",
      "\n",
      "Rank  65\t|\tWord: love\t|\tCount: 2230\t|\tFrequency: 0.232%\n",
      "\n",
      "Rank  66\t|\tWord: well\t|\tCount: 2226\t|\tFrequency: 0.232%\n",
      "\n",
      "Rank  67\t|\tWord: let\t|\tCount: 2207\t|\tFrequency: 0.230%\n",
      "\n",
      "Rank  68\t|\tWord: when\t|\tCount: 2196\t|\tFrequency: 0.228%\n",
      "\n",
      "Rank  69\t|\tWord: them\t|\tCount: 2097\t|\tFrequency: 0.218%\n",
      "\n",
      "Rank  70\t|\tWord: hath\t|\tCount: 2050\t|\tFrequency: 0.213%\n",
      "\n",
      "Rank  71\t|\tWord: than\t|\tCount: 2012\t|\tFrequency: 0.209%\n",
      "\n",
      "Rank  72\t|\tWord: man\t|\tCount: 1972\t|\tFrequency: 0.205%\n",
      "\n",
      "Rank  73\t|\tWord: an\t|\tCount: 1960\t|\tFrequency: 0.204%\n",
      "\n",
      "Rank  74\t|\tWord: one\t|\tCount: 1934\t|\tFrequency: 0.201%\n",
      "\n",
      "Rank  75\t|\tWord: there\t|\tCount: 1912\t|\tFrequency: 0.199%\n",
      "\n",
      "Rank  76\t|\tWord: like\t|\tCount: 1906\t|\tFrequency: 0.198%\n",
      "\n",
      "Rank  77\t|\tWord: upon\t|\tCount: 1884\t|\tFrequency: 0.196%\n",
      "\n",
      "Rank  78\t|\tWord: i'll\t|\tCount: 1876\t|\tFrequency: 0.195%\n",
      "\n",
      "Rank  79\t|\tWord: may\t|\tCount: 1781\t|\tFrequency: 0.185%\n",
      "\n",
      "Rank  80\t|\tWord: make\t|\tCount: 1770\t|\tFrequency: 0.184%\n",
      "\n",
      "Rank  81\t|\tWord: go\t|\tCount: 1762\t|\tFrequency: 0.183%\n",
      "\n",
      "Rank  82\t|\tWord: know\t|\tCount: 1761\t|\tFrequency: 0.183%\n",
      "\n",
      "Rank  83\t|\tWord: did\t|\tCount: 1738\t|\tFrequency: 0.181%\n",
      "\n",
      "Rank  84\t|\tWord: say\t|\tCount: 1732\t|\tFrequency: 0.180%\n",
      "\n",
      "Rank  85\t|\tWord: us\t|\tCount: 1727\t|\tFrequency: 0.180%\n",
      "\n",
      "Rank  86\t|\tWord: were\t|\tCount: 1718\t|\tFrequency: 0.179%\n",
      "\n",
      "Rank  87\t|\tWord: yet\t|\tCount: 1712\t|\tFrequency: 0.178%\n",
      "\n",
      "Rank  88\t|\tWord: should\t|\tCount: 1693\t|\tFrequency: 0.176%\n",
      "\n",
      "Rank  89\t|\tWord: must\t|\tCount: 1627\t|\tFrequency: 0.169%\n",
      "\n",
      "Rank  90\t|\tWord: see\t|\tCount: 1545\t|\tFrequency: 0.161%\n",
      "\n",
      "Rank  91\t|\tWord: had\t|\tCount: 1537\t|\tFrequency: 0.160%\n",
      "\n",
      "Rank  92\t|\tWord: why\t|\tCount: 1520\t|\tFrequency: 0.158%\n",
      "\n",
      "Rank  93\t|\tWord: such\t|\tCount: 1517\t|\tFrequency: 0.158%\n",
      "\n",
      "Rank  94\t|\tWord: 'tis\t|\tCount: 1493\t|\tFrequency: 0.155%\n",
      "\n",
      "Rank  95\t|\tWord: out\t|\tCount: 1458\t|\tFrequency: 0.152%\n",
      "\n",
      "Rank  96\t|\tWord: some\t|\tCount: 1417\t|\tFrequency: 0.147%\n",
      "\n",
      "Rank  97\t|\tWord: give\t|\tCount: 1410\t|\tFrequency: 0.147%\n",
      "\n",
      "Rank  98\t|\tWord: these\t|\tCount: 1397\t|\tFrequency: 0.145%\n",
      "\n",
      "Rank  99\t|\tWord: th'\t|\tCount: 1365\t|\tFrequency: 0.142%\n",
      "\n",
      "Rank 100\t|\tWord: who\t|\tCount: 1333\t|\tFrequency: 0.139%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def write_frequencies(list, number):\n",
    "  rank = 0\n",
    "  sum = 0\n",
    "  all_data = \"\"\n",
    "\n",
    "  for object in list:\n",
    "    sum += int(object[1])\n",
    "  \n",
    "  for object in list[:number]:\n",
    "    rank += 1\n",
    "    token = object[0]\n",
    "    count = object[1]\n",
    "    frequency = float(object[1]) / (sum) * 100\n",
    "    \n",
    "    if(len(token) > 1):\n",
    "        print(\"Rank %3d\\t|\\tWord: %s\\t|\\tCount: %s\\t|\\tFrequency: %5.3f%%\\n\" % (rank, token, count, frequency))\n",
    "    else:\n",
    "        print(\"Rank %3d\\t|\\tWord: %s \\t|\\tCount: %s\\t|\\tFrequency: %5.3f%%\\n\" % (rank, token, count, frequency))\n",
    "\n",
    "\n",
    "write_frequencies(sorted_counts, 100)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Aucun(e)",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}