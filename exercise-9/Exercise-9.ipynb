{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "99e96510",
   "metadata": {},
   "source": [
    "# Exercise 9:\n",
    "\n",
    "In this **exercise** I am trying to understand `Jupyter` by modifying exercise 5.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ce949c9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a', 'midsummer', \"night's\", 'dream', 'by']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "corpus_path = \"../exercise-5/corpus/\"\n",
    "file_paths = [os.path.join(corpus_path, f) for f in os.listdir(corpus_path) if os.path.isfile(os.path.join(corpus_path, f))]\n",
    "\n",
    "tokens = []\n",
    "for path in file_paths:\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        tokens_ = f.read().split()\n",
    "        tokens.extend([token.lower().strip().strip(\".,!?[]()=-\") for token in tokens_])\n",
    "\n",
    "print(tokens[:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9cfe59c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = {}\n",
    "for token in tokens:\n",
    "    if token in counts:\n",
    "        counts[token] = counts[token] + 1\n",
    "    else:\n",
    "        counts[token] = 1\n",
    "        \n",
    "sorted_counts = sorted(counts.items(), key=lambda item: item[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b54381d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token:\tthou\t\t (5864 occurences)\n",
      "Token:\tthy\t\t (4329 occurences)\n",
      "Token:\tshall\t\t (3837 occurences)\n",
      "Token:\tthee\t\t (3309 occurences)\n",
      "Token:\tlord\t\t (3078 occurences)\n",
      "Token:\tgood\t\t (2876 occurences)\n",
      "Token:\tking\t\t (2826 occurences)\n",
      "Token:\tsir\t\t (2765 occurences)\n",
      "Token:\tcome\t\t (2527 occurences)\n",
      "Token:\tenter\t\t (2506 occurences)\n",
      "Token:\twould\t\t (2457 occurences)\n",
      "Token:\to\t\t (2249 occurences)\n",
      "Token:\tlet\t\t (2207 occurences)\n",
      "Token:\tlove\t\t (2199 occurences)\n",
      "Token:\twell\t\t (2192 occurences)\n",
      "Token:\thath\t\t (2049 occurences)\n",
      "Token:\tman\t\t (1947 occurences)\n",
      "Token:\tone\t\t (1917 occurences)\n",
      "Token:\tlike\t\t (1905 occurences)\n",
      "Token:\tupon\t\t (1879 occurences)\n",
      "Token:\ti'll\t\t (1876 occurences)\n",
      "Token:\tmay\t\t (1774 occurences)\n",
      "Token:\tmake\t\t (1770 occurences)\n",
      "Token:\tgo\t\t (1754 occurences)\n",
      "Token:\tknow\t\t (1754 occurences)\n",
      "Token:\tsay\t\t (1725 occurences)\n",
      "Token:\tyet\t\t (1708 occurences)\n",
      "Token:\tus\t\t (1704 occurences)\n",
      "Token:\tmust\t\t (1624 occurences)\n",
      "Token:\tsee\t\t (1537 occurences)\n",
      "Token:\t'tis\t\t (1489 occurences)\n",
      "Token:\tgive\t\t (1407 occurences)\n",
      "Token:\tth'\t\t (1365 occurences)\n",
      "Token:\tfirst\t\t (1295 occurences)\n",
      "Token:\ttake\t\t (1288 occurences)\n",
      "Token:\tmine\t\t (1228 occurences)\n",
      "Token:\t't\t\t (1188 occurences)\n",
      "Token:\tspeak\t\t (1178 occurences)\n",
      "Token:\texit\t\t (1133 occurences)\n",
      "Token:\tnever\t\t (1132 occurences)\n",
      "Token:\texits\t\t (1126 occurences)\n",
      "Token:\ttell\t\t (1102 occurences)\n",
      "Token:\ttime\t\t (1101 occurences)\n",
      "Token:\tthink\t\t (1093 occurences)\n",
      "Token:\tmuch\t\t (1085 occurences)\n",
      "Token:\tduke\t\t (1081 occurences)\n",
      "Token:\tdoth\t\t (1071 occurences)\n",
      "Token:\tqueen\t\t (1044 occurences)\n",
      "Token:\t\t\t (1029 occurences)\n",
      "Token:\theart\t\t (1018 occurences)\n",
      "Token:\tart\t\t (974 occurences)\n",
      "Token:\tgreat\t\t (944 occurences)\n",
      "Token:\tlady\t\t (938 occurences)\n",
      "Token:\tmen\t\t (920 occurences)\n",
      "Token:\thear\t\t (917 occurences)\n",
      "Token:\thand\t\t (914 occurences)\n",
      "Token:\tprince\t\t (902 occurences)\n",
      "Token:\tdeath\t\t (897 occurences)\n",
      "Token:\tlife\t\t (892 occurences)\n",
      "Token:\tmade\t\t (888 occurences)\n",
      "Token:\taside\t\t (888 occurences)\n",
      "Token:\taway\t\t (882 occurences)\n",
      "Token:\tlook\t\t (864 occurences)\n",
      "Token:\tfather\t\t (854 occurences)\n",
      "Token:\tfair\t\t (843 occurences)\n",
      "Token:\tsweet\t\t (838 occurences)\n",
      "Token:\tcannot\t\t (817 occurences)\n",
      "Token:\ttrue\t\t (809 occurences)\n",
      "Token:\tscene\t\t (808 occurences)\n",
      "Token:\tmaster\t\t (783 occurences)\n",
      "Token:\tgod\t\t (782 occurences)\n",
      "Token:\trichard\t\t (781 occurences)\n",
      "Token:\tday\t\t (774 occurences)\n",
      "Token:\ttwo\t\t (773 occurences)\n",
      "Token:\tpray\t\t (771 occurences)\n",
      "Token:\teyes\t\t (770 occurences)\n",
      "Token:\tthus\t\t (763 occurences)\n",
      "Token:\tay\t\t (754 occurences)\n",
      "Token:\tson\t\t (743 occurences)\n",
      "Token:\told\t\t (739 occurences)\n",
      "Token:\tmistress\t\t (708 occurences)\n",
      "Token:\tdone\t\t (701 occurences)\n",
      "Token:\tleave\t\t (700 occurences)\n",
      "Token:\tpoor\t\t (691 occurences)\n",
      "Token:\tsecond\t\t (691 occurences)\n",
      "Token:\twhose\t\t (690 occurences)\n",
      "Token:\ttill\t\t (687 occurences)\n",
      "Token:\tname\t\t (687 occurences)\n",
      "Token:\tthough\t\t (679 occurences)\n",
      "Token:\tcould\t\t (674 occurences)\n",
      "Token:\tfear\t\t (674 occurences)\n",
      "Token:\tnight\t\t (673 occurences)\n",
      "Token:\tblood\t\t (672 occurences)\n",
      "Token:\thonor\t\t (672 occurences)\n",
      "Token:\tnoble\t\t (657 occurences)\n",
      "Token:\tnothing\t\t (653 occurences)\n",
      "Token:\tfool\t\t (653 occurences)\n",
      "Token:\tworld\t\t (652 occurences)\n",
      "Token:\ttherefore\t\t (644 occurences)\n",
      "Token:\tcomes\t\t (641 occurences)\n"
     ]
    }
   ],
   "source": [
    "stop_words = []\n",
    "with open(\"stopwords.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    stop_words = f.read().split()\n",
    "\n",
    "filtered_counts = [ (word, frequency) for (word, frequency) in sorted_counts if word not in stop_words ]\n",
    "\n",
    "for (token, frequency) in filtered_counts[:100]:\n",
    "    print(\"Token:\\t{token}\\t\\t ({frequency} occurences)\".format(token=token, frequency=frequency))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28c918b9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
